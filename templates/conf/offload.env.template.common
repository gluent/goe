#!/bin/bash

# Copyright 2016 The GOE Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# SSL settings:
# SSL_ACTIVE identifies when the backend SQL engine is using SSL
#export SSL_ACTIVE=true
#export SSL_TRUSTED_CERTS=

# Path to GOE encryption key file if using encrypted passwords
#export PASSWORD_KEY_FILE=

# Offload Transport Settings:
# The method used to transport data from an RDBMS frontend to a backend, defaults to AUTO
# Valid values are AUTO, GOE, GCP and SQOOP
export OFFLOAD_TRANSPORT=AUTO
# User to authenticate as for executing Offload Transport commands such as SSH for spark-submit or Sqoop commands, or Livy API calls
export OFFLOAD_TRANSPORT_USER=${USER}
# Degree of transport parallelism
export OFFLOAD_TRANSPORT_PARALLELISM=2
# OFFLOAD_TRANSPORT_CMD_HOST host for running data transport commands such as spark-submit or Sqoop commands
export OFFLOAD_TRANSPORT_CMD_HOST="localhost"
# Control whether parallel data transport tasks should have a consistent point in time when reading RDBMS data
export OFFLOAD_TRANSPORT_CONSISTENT_READ=true
# Number of records to fetch in a single batch from the RDBMS during Offload
export OFFLOAD_TRANSPORT_FETCH_SIZE=
# Maximum table size to use Query Import transport method
export OFFLOAD_TRANSPORT_SMALL_TABLE_THRESHOLD=20M
# OFFLOAD_TRANSPORT_SPARK_THRIFT_HOST host(s) where the Spark Thrift Server is running
# OFFLOAD_TRANSPORT_SPARK_THRIFT_HOST can be a comma-separated list to randomly choose from, eg. hdp21,hdp22,hdp23
export OFFLOAD_TRANSPORT_SPARK_THRIFT_HOST=
export OFFLOAD_TRANSPORT_SPARK_THRIFT_PORT=
# The executable to use for submitting Spark applications. Can be empty, spark-submit or spark2-submit
export OFFLOAD_TRANSPORT_SPARK_SUBMIT_EXECUTABLE=
# The master URL for the Spark cluster, only used for non-Hadoop Spark clusters, if empty Spark will use default settings
export OFFLOAD_TRANSPORT_SPARK_SUBMIT_MASTER_URL="spark://${OFFLOAD_TRANSPORT_CMD_HOST}:7077"
# Yarn queue name for GOE Spark jobs
export OFFLOAD_TRANSPORT_SPARK_QUEUE_NAME=
# Override JVM flags for spark-submit command, inserted right after "spark-submit", e.g.:
#     "-Dhadoop.security.credential.provider.path=jceks://hdfs/user/goe/dbname.dbuser.pwd.m.jceks"
# For Oracle wallet usage this may be useful as below:
#     "-Doracle.net.tns_admin=. -Doracle.net.wallet_location=(SOURCE=(METHOD=FILE)(METHOD_DATA=(DIRECTORY=.)))"
# This setting is ignored for OFFLOAD_TRANSPORT values that do not utilise Spark
export OFFLOAD_TRANSPORT_SPARK_OVERRIDES=
# Key/value pairs, in JSON format, to override Spark property defaults, e.g.:
#     export OFFLOAD_TRANSPORT_SPARK_PROPERTIES='{"spark.extraListeners": "GOETaskListener", "spark.executor.memory": "4G"}'
# spark.extraListeners: GOETaskListener is required for Offload Transport verification. Extra listeners may be added to the JSON below.
export OFFLOAD_TRANSPORT_SPARK_PROPERTIES='{"spark.extraListeners": "GOETaskListener", "spark.jars.packages": "com.oracle.database.jdbc:ojdbc11:23.2.0.0,org.apache.spark:spark-avro_2.12:3.3.0"}'
# CSV of files to be passed to Spark. Does not apply to Thriftserver or Livy transport methods.
export OFFLOAD_TRANSPORT_SPARK_FILES=
# CSV of JAR files to be passed to Spark. Does not apply to Thriftserver or Livy transport methods.
export OFFLOAD_TRANSPORT_SPARK_JARS=
# URL for Livy/Spark REST API, e.g.:
#      http://fqdn-n.example.com:port
export OFFLOAD_TRANSPORT_LIVY_API_URL=
# OFFLOAD_TRANSPORT_LIVY_API_VERIFY_SSL is used to enable SSL for REST API calls. There are 4 states:
#   Empty: Do not use SSL
#   TRUE: Use SSL & verify certificate against known certificates
#   FALSE: Use SSL & do not verify certificate
#   /some/path/here/cert-bundle.crt: Use SSL & verify certificate against path to certificate bundle
export OFFLOAD_TRANSPORT_LIVY_API_VERIFY_SSL=
# Idle timeout (in seconds) for Spark client sessions created in Livy
export OFFLOAD_TRANSPORT_LIVY_IDLE_SESSION_TIMEOUT=
# OFFLOAD_TRANSPORT_LIVY_MAX_SESSIONS is used to limit the number of Livy sessions Offload will create
# Sessions are re-used when idle, new sessions are only created when no idle sessions are available
export OFFLOAD_TRANSPORT_LIVY_MAX_SESSIONS=
# Database connection details for data transport if different to ORA_CONN
export OFFLOAD_TRANSPORT_DSN=
# Key/value pairs, in JSON format, to supply Oracle ALTER SESSION parameter values
# These only take effect during data transport, e.g.:
#     export OFFLOAD_TRANSPORT_RDBMS_SESSION_PARAMETERS='{"cell_offload_processing": "false"}'
export OFFLOAD_TRANSPORT_RDBMS_SESSION_PARAMETERS=
# Polling interval in seconds for validation of Spark transport row count.
# A value of -1 disables retrieval of RDBMS SQL statistics.
# A value of 0 disables polling resulting in a single capture of SQL statistics after Offload Transport.
# A value greater than 0 polls RDBMS SQL statistics using the specified interval.
#export OFFLOAD_TRANSPORT_VALIDATION_POLLING_INTERVAL=0

# info/detail/debug, default info
export LOG_LEVEL=info

# Restrict default size of RDBMS partitions offloaded per cycle. [\d.]+[MG] eg. 100M, 1G, 1.5G
#export MAX_OFFLOAD_CHUNK_SIZE=
# Restrict default number of RDBMS partitions offloaded per cycle.
#export MAX_OFFLOAD_CHUNK_COUNT=

# Default degree of parallelism to use for the RDBMS query executed when validating an offload.
# Values or 0 or 1 will execute the query without parallelism.
# Values > 1 will force a parallel query of the given degree.
# If unset, the RDBMS query will fall back to using the behavior specified by RDBMS defaults.
#export OFFLOAD_VERIFY_PARALLELISM=

# ===========================================================================================
# Advanced common settings: you probably do not need to modify these lines
# ===========================================================================================

# Database name/path prefix for multi-tenant support
#  if undefined, the DB_UNIQUE_NAME will be used, giving <DB_UNIQUE_NAME>_<schema>
#  if defined but empty, no prefix is used, giving <schema>
#  otherwise, databases will be named <DB_NAME_PREFIX>_<schema>
export DB_NAME_PREFIX=

# Paths
export PATH=${OFFLOAD_HOME}/bin:$PATH:$KERBEROS_PATH

# Override config path, defaults to OFFLOAD_HOME/conf
export OFFLOAD_CONFDIR=${OFFLOAD_HOME}/conf

# Override log path, defaults to OFFLOAD_HOME/log
# Also supports Google Cloud Storage paths, e.g.: gs://my-bucket/my-prefix
#export OFFLOAD_LOGDIR=

# Default number of external table location files for parallel data retrieval
export NUM_LOCATION_FILES=16

# Default method of generation for backend stats after an Offload, Incremental Update Extraction or Compaction (supported values: NATIVE, HISTORY, COPY, NONE).
# Can override with command-line options if required.
#   - NATIVE:  Use Impala or Hive native stats gathering commands or methods (this is the default)
#   - HISTORY: Gather stats on all partitions without stats. Only applicable to an Offload on Hive (for Impala, HISTORY will be converted to NATIVE)
#   - COPY:    Copy RDBMS stats to the backend table using ALTER TABLE commands. Only applicable to an Offload on Impala
#   - NONE:    Don't compute or copy any stats
#export OFFLOAD_STATS_METHOD=COPY

# Compress load table data during an Offload. This can be useful when staging to cloud storage.
#export OFFLOAD_COMPRESS_LOAD_TABLE=true

# Propagate NOT NULL constraints to the backend system during Offload
#   - AUTO: Propagate NOT NULL constraints to the backend system
#   - NONE: Don't copy any NOT NULL constraints
export OFFLOAD_NOT_NULL_PROPAGATION=AUTO

# Distribute data by partition key(s) during the final INSERT operation of an offload. Hive only (will be ignored for Impala).
# Defaults to true
export OFFLOAD_DISTRIBUTE_ENABLED=true
