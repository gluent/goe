# Copyright 2016 The GOE Authors. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ===========================================================================================
# Google BigQuery settings
# ===========================================================================================

# Path to Google service account private key JSON file
# GOOGLE_APPLICATION_CREDENTIALS=

# Backend distribution:
BACKEND_DISTRIBUTION=GCP

# Orchestration query engine
QUERY_ENGINE=BIGQUERY

# Google BigQuery location to use when creating a dataset, this has no impact other than when creating datasets.
# The default is to use the BigQuery default.
# Note the dataset location must be compatible with that of the bucket specified in OFFLOAD_FS_CONTAINER
BIGQUERY_DATASET_LOCATION=

# Project to use for BigQuery table references.
# The default is to use the default project for the authenticated user/service account.
BIGQUERY_DATASET_PROJECT=

# Google Cloud Key Management Service crytopgraphic key information for customer-managed encryption keys (CMEK)
# GOOGLE_KMS_KEY_RING_PROJECT only needs to be set if the KMS project differs from the default
# project for the authenticated user/service account.
GOOGLE_KMS_KEY_RING_PROJECT=
GOOGLE_KMS_KEY_RING_LOCATION=
GOOGLE_KMS_KEY_RING_NAME=
GOOGLE_KMS_KEY_NAME=

# Google Dataproc cluster name
GOOGLE_DATAPROC_CLUSTER=
# Google Dataproc/Dataproc Batches project
GOOGLE_DATAPROC_PROJECT=
# Google Dataproc/Dataproc Batches region
GOOGLE_DATAPROC_REGION=
# Google Dataproc/Dataproc Batches service account
GOOGLE_DATAPROC_SERVICE_ACCOUNT=
# Google Dataproc Batches version, leave blank to disable Dataproc Batches
GOOGLE_DATAPROC_BATCHES_VERSION=
# Google Dataproc Batches subnet
# GOOGLE_DATAPROC_BATCHES_SUBNET defines a full subnet URI, for example:
#   projects/my-project/regions/my-region/subnetworks/my-subnet
GOOGLE_DATAPROC_BATCHES_SUBNET=
# Google Dataproc Batches TTL
GOOGLE_DATAPROC_BATCHES_TTL=2d

# Filesystem type for Offloaded tables
# When offloading a table to cloud storage the table LOCATION will be structured as below:
#   ${OFFLOAD_FS_SCHEME}://${OFFLOAD_FS_CONTAINER}/${OFFLOAD_FS_PREFIX}/db_name/table_name/
OFFLOAD_FS_SCHEME=gs
# The path with which to prefix offloaded table paths.
OFFLOAD_FS_PREFIX=goe
# A valid bucket or container name when offloading to cloud storage
OFFLOAD_FS_CONTAINER=

# File format for staged data during an Offload (supported values: AVRO and PARQUET)
OFFLOAD_STAGING_FORMAT=AVRO

# Key/value pairs, in JSON format, defining session query parameters for the orchestration backend query engine.
# These take effect for all queries issued to the query engine, e.g:
#     OFFLOAD_BACKEND_SESSION_PARAMETERS="{\"parameter_name\": \"some.value\"}"
#OFFLOAD_BACKEND_SESSION_PARAMETERS=

# Case conversion to be applied to any backend identifier names created by GOE (supported values: UPPER, LOWER and NO_MODIFY).
BACKEND_IDENTIFIER_CASE=LOWER

# Authentication mechanism for Spark ThriftServer
HIVE_SERVER_AUTH_MECHANISM=PLAIN
